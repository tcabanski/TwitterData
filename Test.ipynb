{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "291b76f7-1817-41e3-920e-6e9720d528ba",
   "metadata": {},
   "source": [
    "__Initialization__\n",
    "\n",
    "Assumes Python 3\n",
    "\n",
    "---------------- Only run once on the machine to get things configured -------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc1d65e8-ecfc-4645-a617-30bd58eae4fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "!echo 'This could take awhile. Status at bottom will show idle when done.'\n",
    "!git clone https://github.com/JustAnotherArchivist/snscrape\n",
    "!echo done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e251b62-2409-4897-92b2-21c0b8a359c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!echo 'This could take awhile. Status at bottom will show idle when done.'\n",
    "!pip install snscrape\n",
    "!pip install pandas\n",
    "!pip install seaborn\n",
    "!echo done"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcf3f043-4c2c-4ddb-a301-71f6947862d8",
   "metadata": {},
   "source": [
    "---------------------------- Below here can be run multiple times --------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "017f454a-00b8-41cf-84b1-baebe543ae4c",
   "metadata": {},
   "source": [
    "__Parse tweets into a Pandas data set__\n",
    "\n",
    "Have to run this before trying to prepare the dataset for plotting or plotting.\n",
    "\n",
    "Parameters\n",
    "\n",
    "* Set workingDataMaxRows to None (workingDataMaxRows = None) to show all rows or use a number, like 10, to limit ouput (workingDataMaxRows = 10)\n",
    "* Set maxResults to None if you want all tweets or limit by setting a number\n",
    "* Set since to None for all dates or use YYYY-MM-DD format to get all tweets since that date\n",
    "* Set showWorkingData to True to show data grids with sample data at each step\n",
    "* Set filePrefix to something descriptive so you know which files to download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed7ea712-f327-41da-a726-d292d476de51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas\n",
    "import seaborn\n",
    "import os\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Parameters\n",
    "workingDataMaxRows = 10\n",
    "maxResults = None\n",
    "since = '2020-01-01'\n",
    "twitterUser = 'atrupar'\n",
    "filePrefix = 'atrupar'\n",
    "showWorkingData = False\n",
    "\n",
    "#functions\n",
    "\n",
    "def scrape_twitter():\n",
    "    if maxResults is None:\n",
    "        maxResultsParam = ''\n",
    "    else:\n",
    "        maxResultsParam = f'--max-results {maxResults}'\n",
    "    \n",
    "    if since is None:\n",
    "        sinceParam = ''\n",
    "    else:\n",
    "        sinceParam = f'--since {since}'\n",
    "\n",
    "    print(f'Running: snscrape {maxResultsParam} --jsonl {sinceParam} twitter-user {twitterUser}')\n",
    "    print('This can take awhile. The status bar at the bottom of the screen will say Busy until this is done.')\n",
    "\n",
    "    results  = !snscrape {maxResultsParam} --jsonl {sinceParam} twitter-user {twitterUser}\n",
    "\n",
    "    print('Done scraping Twitter')\n",
    "    \n",
    "    return results\n",
    "\n",
    "def build_data_frame(results):\n",
    "    temp = []\n",
    "    \n",
    "    for json_str in results:\n",
    "        result = json.loads(json_str)\n",
    "    \n",
    "        isVideo = False\n",
    "        isImage = False\n",
    "        mediaType = 'None'\n",
    "        views = 0\n",
    "        media = result['media']\n",
    "        if (media is None) == False and len(media) > 0:\n",
    "            if media[0]['_type'] == 'snscrape.modules.twitter.Photo':\n",
    "                isImage = True\n",
    "                mediaType = 'Image'\n",
    "            elif media[0]['_type'] == 'snscrape.modules.twitter.Video':\n",
    "                isVideo = True\n",
    "                mediaType = 'Video'\n",
    "                views = media[0]['views']\n",
    "                if views is None:\n",
    "                    views = 0\n",
    "\n",
    "        totalEngagement =  result['replyCount'] + result['retweetCount'] + result['likeCount'] + result['quoteCount']\n",
    "        totalEnagementWithVideoViews = totalEngagement + views\n",
    "\n",
    "        record = {\n",
    "            'TweetId': result['id'],\n",
    "            'TweetDate': result['date'],\n",
    "            'Replies': result['replyCount'],\n",
    "            'Retweets': result['retweetCount'],\n",
    "            'Likes': result['likeCount'],\n",
    "            'Quotes': result['quoteCount'],\n",
    "            'Source': result['sourceLabel'],\n",
    "            'IsVideo': isVideo,\n",
    "            'IsImage': isImage,\n",
    "            'VideoViews': views,\n",
    "            'MediaType': mediaType,\n",
    "            'TotalEngagement':totalEngagement,\n",
    "            'TotalEngagementWithVideoViews':totalEnagementWithVideoViews\n",
    "        }\n",
    "\n",
    "        temp.append(record)\n",
    "\n",
    "    output = pandas.DataFrame(temp)\n",
    "\n",
    "    # Put TweetDate into proper date format\n",
    "    output['TweetDate'] = pandas.to_datetime(output['TweetDate'])\n",
    "\n",
    "    if showWorkingData:\n",
    "        with pandas.option_context('display.max_rows', workingDataMaxRows,):\n",
    "            display(output)\n",
    "            \n",
    "    return output\n",
    "\n",
    "def output_raw(df):\n",
    "    df.to_csv(f'{filePrefix}_RawData.csv')\n",
    "    print('File created')\n",
    "\n",
    "def create_scatter_plots(df):\n",
    "    seaborn.set(style='whitegrid')\n",
    "\n",
    "    outputGroupedByMediaType = df.groupby(['MediaType', pandas.Grouper(key='TweetDate', freq='W-MON')]).agg({'TotalEngagement':'sum','TotalEngagementWithVideoViews':'sum'}).reset_index().sort_values('TweetDate')\n",
    "    if showWorkingData:\n",
    "        with pandas.option_context('display.max_rows', workingDataMaxRows,):\n",
    "            display(outputGroupedByMediaType)\n",
    "\n",
    "    plt.figure(figsize=(20, 5))\n",
    "    scatter2 = seaborn.scatterplot(x='TweetDate', y='TotalEngagement', hue = 'MediaType', data=outputGroupedByMediaType).set(title='Total Enagement (Log scale)', yscale='log')\n",
    "    lgd = plt.legend(loc='upper right', bbox_to_anchor=(1.15, 1))\n",
    "    plt.savefig(f'{filePrefix}_TotalEnagementByMediaTypeLogScale.png', bbox_extra_artists=(lgd,), bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "    outputGroupedBySource = df.groupby(['Source', pandas.Grouper(key='TweetDate', freq='W-MON')]).agg({'TotalEngagement':'sum','TotalEngagementWithVideoViews':'sum'}).reset_index().sort_values('TweetDate')\n",
    "    if showWorkingData:\n",
    "        with pandas.option_context('display.max_rows', workingDataMaxRows,):\n",
    "            display(outputGroupedBySource)\n",
    "\n",
    "    plt.figure(figsize=(20, 5))\n",
    "    scatter3 = seaborn.scatterplot(x='TweetDate', y='TotalEngagement', hue = 'Source', data=outputGroupedBySource).set(title='Total Enagement by Source (Log scale)', yscale='log')\n",
    "    lgd = plt.legend(loc='upper right', bbox_to_anchor=(1.15, 1))\n",
    "    plt.savefig(f'{filePrefix}_TotalEnagementBySourceLogScale.png', bbox_extra_artists=(lgd,), bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(figsize=(20, 5))\n",
    "    scatter4 = seaborn.scatterplot(x='TweetDate', y='TotalEngagementWithVideoViews', hue = 'Source', data=outputGroupedBySource).set(title='Total Enagement by Source with Video Views (Log scale)', yscale='log')\n",
    "    lgd = plt.legend(loc='upper right', bbox_to_anchor=(1.15, 1))\n",
    "    plt.savefig(f'{filePrefix}_TotalEnagementBySourceIncludingVideoViewsLogScale.png', bbox_extra_artists=(lgd,), bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"Files starting with '{filePrefix}_' are the ones that contain your CSV data and charts\")\n",
    "    \n",
    "def clean_output_files():\n",
    "    for filename in glob.glob(f\"{filePrefix}_*\"):\n",
    "        os.remove(filename) \n",
    "    \n",
    "#main\n",
    "clean_output_files()\n",
    "results = scrape_twitter()\n",
    "df = build_data_frame(results)\n",
    "output_raw(df)\n",
    "create_scatter_plots(df)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
